{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c41472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7b888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "014-3_fingering.txt\n",
      "   noteID  onset_time  offset_time spelled_pitch  onset_velocity  \\\n",
      "0       0    0.006978     0.363573            C5              67   \n",
      "1       1    0.364271     0.714585            C5              64   \n",
      "2       2    0.715283     1.071180            C5              64   \n",
      "3       3    1.072920     1.588110            C5              69   \n",
      "4       4    1.072920     3.222690            F3              56   \n",
      "5       5    1.072920     3.222690            A3              56   \n",
      "6       6    1.072920     3.222690            C4              70   \n",
      "7       7    1.620580     1.682360            D5              64   \n",
      "8       8    1.686550     1.749370            C5              64   \n",
      "9       9    1.753560     1.815340            B4              64   \n",
      "\n",
      "   offset_velocity  channel finger_number  \n",
      "0               80        0             3  \n",
      "1               80        0             2  \n",
      "2               80        0             3  \n",
      "3               80        0             2  \n",
      "4               80        1            -5  \n",
      "5               80        1            -3  \n",
      "6               80        1            -1  \n",
      "7               80        0             3  \n",
      "8               80        0             2  \n",
      "9               80        0             1  \n"
     ]
    }
   ],
   "source": [
    "directory_path = 'PianoFingeringDataset_v1.2/PianoFingeringDataset_v1.2/FingeringFiles/'\n",
    "\n",
    "\n",
    "\n",
    "# Loads in ONE big CONCATENATED dataset from ALL dataframes\n",
    "# my_dfs = []\n",
    "\n",
    "# for filename in os.listdir(directory_path):\n",
    "#     file_path = os.path.join(directory_path, filename)\n",
    "#     if os.path.isfile(file_path):\n",
    "#         df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
    "#         my_dfs.append(df)\n",
    "# #         print(df)\n",
    "        \n",
    "# big_df = pd.concat(my_dfs)\n",
    "# print(big_df)\n",
    "\n",
    "\n",
    "# load in just the fingering for 014-3: Mozart Piano Sonata K 330 in C major, 2nd mov.\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[0]:\n",
    "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
    "        print(filename)\n",
    "        print(df.head(10))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caef95f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noteID             0\n",
       "onset_time         0\n",
       "offset_time        0\n",
       "spelled_pitch      0\n",
       "onset_velocity     0\n",
       "offset_velocity    0\n",
       "channel            0\n",
       "finger_number      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ee2a7",
   "metadata": {},
   "source": [
    "# Idea 1: simple linear regression to predict finger_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10eeea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'A6': 5, 'B1': 6, 'B2': 7, 'B3': 8, 'B4': 9, 'B5': 10, 'B6': 11, 'Bb1': 12, 'Bb2': 13, 'Bb3': 14, 'Bb4': 15, 'Bb5': 16, 'Bb6': 17, 'C#1': 18, 'C#2': 19, 'C#3': 20, 'C#4': 21, 'C#5': 22, 'C#6': 23, 'C#7': 24, 'C1': 25, 'C2': 26, 'C3': 27, 'C4': 28, 'C5': 29, 'C6': 30, 'C7': 31, 'D1': 32, 'D2': 33, 'D3': 34, 'D4': 35, 'D5': 36, 'D6': 37, 'D7': 38, 'E1': 39, 'E2': 40, 'E3': 41, 'E4': 42, 'E5': 43, 'E6': 44, 'E7': 45, 'Eb1': 46, 'Eb2': 47, 'Eb3': 48, 'Eb4': 49, 'Eb5': 50, 'Eb6': 51, 'Eb7': 52, 'F#1': 53, 'F#2': 54, 'F#3': 55, 'F#4': 56, 'F#5': 57, 'F#6': 58, 'F#7': 59, 'F1': 60, 'F2': 61, 'F3': 62, 'F4': 63, 'F5': 64, 'F6': 65, 'F7': 66, 'G#1': 67, 'G#2': 68, 'G#3': 69, 'G#4': 70, 'G#5': 71, 'G#6': 72, 'G1': 73, 'G2': 74, 'G3': 75, 'G4': 76, 'G5': 77, 'G6': 78}\n"
     ]
    }
   ],
   "source": [
    "spelled_pitch_values = set()\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
    "        spelled_pitch_values.update(df['spelled_pitch'].unique())\n",
    "\n",
    "\n",
    "\n",
    "# convert \"spelled pitch\" field to a number: create the mapping in the first place\n",
    "spelled_pitch_values = sorted(spelled_pitch_values)\n",
    "\n",
    "pitch_to_int_mapping = {p:i for i, p in enumerate(spelled_pitch_values)}\n",
    "\n",
    "# print(len(spelled_pitch_values))\n",
    "# print(len(pitch_to_int_mapping))\n",
    "print(pitch_to_int_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8552f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape is torch.Size([289, 7])\n",
      "y's shape is torch.Size([289, 1])\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[0]:\n",
    "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
    "\n",
    "num_data, num_features = df.shape\n",
    "x = df.iloc[:, 0:num_features - 1]\n",
    "y = df.iloc[:, num_features - 1]\n",
    "\n",
    "\n",
    "# convert \"spelled pitch\" field to a number\n",
    "x['spelled_pitch'] = x['spelled_pitch'].map(pitch_to_int_mapping)\n",
    "\n",
    "\n",
    "x = torch.tensor(x.values.tolist(), dtype=torch.float32)\n",
    "y = torch.tensor(y.values.astype(float).tolist())\n",
    "y = y.unsqueeze(1)   # conver from size [289] to size [289, 1]\n",
    "\n",
    "print(f\"x's shape is {x.shape}\")\n",
    "print(f\"y's shape is {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264b9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features is 8 and num data is 289\n"
     ]
    }
   ],
   "source": [
    "print(f\"num features is {num_features} and num data is {num_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ebc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch code that does the same least squares fitting, but nn.Module-ized. Iterative regression\n",
    "\n",
    "class LinearRegressionBaseline(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(LinearRegressionBaseline, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc5b8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([289, 7])\n",
      "torch.Size([289, 1])\n",
      "torch.Size([289, 1])\n"
     ]
    }
   ],
   "source": [
    "my_linear_model = LinearRegressionBaseline(num_features - 1, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(my_linear_model.parameters(), lr=1e-2)    # Needs a VERY small learning rate, else NaN.\n",
    "\n",
    "\n",
    "# normalize inputs before feeding to model\n",
    "x = (x - x.mean()) / x.std()\n",
    "y = (y - y.mean()) / y.std()\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(my_linear_model(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc6809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5000/5000], Loss: 0.7610\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = my_linear_model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "#     print(y_pred)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5000 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91667def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Test Loss: 0.0652\n",
      "Sample Predictions:\n",
      "Predicted: [0.58792406], Actual: [0.5881754]\n",
      "Predicted: [0.45260912], Actual: [0.3511005]\n",
      "Predicted: [0.42795092], Actual: [0.5881754]\n",
      "Predicted: [0.5051299], Actual: [0.3511005]\n",
      "Predicted: [-1.2873812], Actual: [-1.3084236]\n"
     ]
    }
   ],
   "source": [
    "# Check on testing set\n",
    "\n",
    "x_test = x\n",
    "y_test = y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure your model is in evaluation mode\n",
    "my_linear_model.eval()\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    # Forward pass: Predict on the test set\n",
    "    y_test_pred = my_linear_model(x_test)\n",
    "    \n",
    "    # Calculate the loss on the test set\n",
    "    test_loss = criterion(y_test_pred, y_test)\n",
    "    \n",
    "    # Optional: Convert predictions to numpy for further analysis if needed\n",
    "    y_test_pred_np = y_test_pred.cpu().numpy() if y_test_pred.is_cuda else y_test_pred.numpy()\n",
    "    y_test_np = y_test.cpu().numpy() if y_test.is_cuda else y_test.numpy()\n",
    "    \n",
    "# Print the results\n",
    "print(\"Test Results:\")\n",
    "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "print(\"Sample Predictions:\")\n",
    "for i in range(min(5, len(y_test_pred))):  # Display up to 5 predictions\n",
    "    print(f\"Predicted: {y_test_pred_np[i]}, Actual: {y_test_np[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "309a6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 7)\n",
      "(289,)\n",
      "Weights (Scikit-Learn): [-7.6401695e+01  7.0771492e-01 -5.0004215e+00  1.7104356e+00\n",
      "  1.4574406e-01  1.8301501e+00  2.8230651e-10 -7.2942490e+01]\n",
      "Test Loss (Scikit-Learn): 0.53009546\n"
     ]
    }
   ],
   "source": [
    "# Compare with Scikit Normal Equation Result\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "\n",
    "# Assuming x and y are your training tensors\n",
    "x_np = x.numpy() if isinstance(x, torch.Tensor) else x\n",
    "y_np = y.numpy() if isinstance(y, torch.Tensor) else y\n",
    "y_np = y_np.reshape(-1) \n",
    "\n",
    "print(x_np.shape)\n",
    "print(y_np.shape)\n",
    "\n",
    "\n",
    "# Validate with Scikit-Learn\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(x_np, y_np)\n",
    "\n",
    "# Print Scikit-Learn weights for comparison\n",
    "print(\"Weights (Scikit-Learn):\", np.hstack([lr.intercept_, lr.coef_]))\n",
    "\n",
    "\n",
    "x_test_np = x_np\n",
    "y_test_np = y_np\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = lr.predict(x_test_np)\n",
    "\n",
    "# Compute Mean Squared Error (MSE) loss\n",
    "test_loss = np.mean((y_test_pred - y_test_np) ** 2)\n",
    "\n",
    "# Print the loss\n",
    "print(\"Test Loss (Scikit-Learn):\", test_loss)    # About the same loss: 0.53!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1572f",
   "metadata": {},
   "source": [
    "# Idea 2: Add more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1104c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep neural net with more layers\n",
    "\n",
    "class DeepNeuralNet(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(DeepNeuralNet, self).__init__()\n",
    "        self.mlp_layer = nn.Sequential(\n",
    "            nn.Linear(input_dims, 4 * input_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * input_dims, output_dims),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4971d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([289, 7])\n",
      "torch.Size([289, 1])\n",
      "torch.Size([289, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     print(x.shape)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#     print(y.shape)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     print(y_pred)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/projects/smolgrad/smol/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/smolgrad/smol/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/smolgrad/smol/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dnn_model = DeepNeuralNet(num_features - 1, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-2)    # Needs a VERY small learning rate, else NaN.\n",
    "\n",
    "\n",
    "# normalize inputs before feeding to model\n",
    "x = (x - x.mean()) / x.std()\n",
    "y = (y - y.mean()) / y.std()\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(dnn_model(x).shape)\n",
    "\n",
    "\n",
    "# Adding more layers helps a lot!\n",
    "\n",
    "epochs = 50000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = dnn_model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "#     print(y_pred)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5000 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44042739",
   "metadata": {},
   "source": [
    "# Testing code\n",
    "\n",
    "Testing on some random other piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1db253f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "026-5_fingering.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[1]:\n",
    "        test_df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
    "        print(filename)\n",
    "        \n",
    "x_test = test_df.iloc[:, 0:num_features - 1]\n",
    "y_test = test_df.iloc[:, num_features - 1]\n",
    "\n",
    "x_test['spelled_pitch'] = x_test['spelled_pitch'].map(pitch_to_int_mapping)\n",
    "\n",
    "\n",
    "# print(x_test)\n",
    "\n",
    "# NORMALIZE FIRST\n",
    "# Normalize x_test\n",
    "for col in x_test.columns:\n",
    "    std = x_test[col].std()\n",
    "    if std == 0:  # Check if all values are the same\n",
    "        x_test[col] = 0  # Assign all entries in this column to 0\n",
    "    else:\n",
    "        x_test[col] = (x_test[col] - x_test[col].mean()) / std\n",
    "\n",
    "# Normalize y_test\n",
    "y_test_std = y_test.std()\n",
    "if y_test_std == 0:  # Check if all values are the same\n",
    "    y_test = 0  # Assign all entries in y_test to 0\n",
    "else:\n",
    "    y_test = (y_test - y_test.mean()) / y_test_std\n",
    "\n",
    "\n",
    "\n",
    "x_test = torch.tensor(x_test.values.tolist(), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values.astype(float).tolist())\n",
    "y_test = y_test.unsqueeze(1)   # conver from size [289] to size [289, 1]\n",
    "\n",
    "\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(x_test.isna().sum())\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c09892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Test Loss: 6451.8745\n",
      "Sample Predictions:\n",
      "Predicted: [19.623936], Actual: [0.29965785]\n",
      "Predicted: [20.528217], Actual: [0.6164696]\n",
      "Predicted: [19.723484], Actual: [1.566905]\n",
      "Predicted: [-141.30074], Actual: [-1.6012129]\n",
      "Predicted: [-140.98277], Actual: [-0.33396572]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check on testing set\n",
    "\n",
    "# x_test = x\n",
    "# y_test = y\n",
    "\n",
    "# print(x_test)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# Ensure your model is in evaluation mode\n",
    "dnn_model.eval()\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    # Forward pass: Predict on the test set\n",
    "    y_test_pred = dnn_model(x_test)\n",
    "    \n",
    "    # Calculate the loss on the test set\n",
    "    test_loss = criterion(y_test_pred, y_test)\n",
    "    \n",
    "    # Optional: Convert predictions to numpy for further analysis if needed\n",
    "    y_test_pred_np = y_test_pred.cpu().numpy() if y_test_pred.is_cuda else y_test_pred.numpy()\n",
    "    y_test_np = y_test.cpu().numpy() if y_test.is_cuda else y_test.numpy()\n",
    "    \n",
    "# Print the results\n",
    "print(\"Test Results:\")\n",
    "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "print(\"Sample Predictions:\")\n",
    "for i in range(min(5, len(y_test_pred))):  # Display up to 5 predictions\n",
    "    print(f\"Predicted: {y_test_pred_np[i]}, Actual: {y_test_np[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea5c38",
   "metadata": {},
   "source": [
    "# Idea 3: Seq to Seq Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ed3c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Recurrent Neural Network\n",
    "\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "i = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(i, h0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdfd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class smolRNN(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, num_layers=2):\n",
    "        super(smolRNN, self).__init__()\n",
    "        \n",
    "        self.rnn_layer = nn.Sequential(\n",
    "            nn.RNN(input_dims, 4 * input_dims, num_layers),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9dbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smol)",
   "language": "python",
   "name": "smol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
