{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/auto-pian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVOCZjvKnHpj",
        "outputId": "ac31ac53-a7cb-4948-f108-a383f68273ef"
      },
      "id": "AVOCZjvKnHpj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1jn_llb-3OnamAo89wMXsdDKi__iyjswV/auto-pian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7c41472",
      "metadata": {
        "id": "b7c41472"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2d7b888e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7b888e",
        "outputId": "2ca472c8-93de-4ced-8b12-6b45743773d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117-1_fingering.txt\n",
            "   noteID  onset_time  offset_time spelled_pitch  onset_velocity  \\\n",
            "0       0     1.50000      1.66650            A4              62   \n",
            "1       1     1.50000      1.66650            A5              62   \n",
            "2       2     1.66650      1.83349           Bb4              62   \n",
            "3       3     1.66650      1.83349           Bb5              62   \n",
            "4       4     1.83349      2.00000            A4              62   \n",
            "5       5     1.83349      2.00000            A5              62   \n",
            "6       6     2.00000      2.66650           G#5              62   \n",
            "7       7     2.00000      3.49999           G#4              62   \n",
            "8       8     2.00000      2.16650            D2              62   \n",
            "9       9     2.16650      2.33349           Bb2              62   \n",
            "\n",
            "   offset_velocity  channel  finger_number  \n",
            "0               80        0              1  \n",
            "1               80        0              5  \n",
            "2               80        0              1  \n",
            "3               80        0              4  \n",
            "4               80        0              1  \n",
            "5               80        0              5  \n",
            "6               80        0              4  \n",
            "7               80        0              1  \n",
            "8               80        1             -5  \n",
            "9               80        1             -2  \n"
          ]
        }
      ],
      "source": [
        "directory_path = 'PianoFingeringDataset_v1.2/PianoFingeringDataset_v1.2/FingeringFiles/'\n",
        "\n",
        "# Loads in ONE big CONCATENATED dataset from ALL dataframes\n",
        "# my_dfs = []\n",
        "\n",
        "# for filename in os.listdir(directory_path):\n",
        "#     file_path = os.path.join(directory_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#         df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
        "#         my_dfs.append(df)\n",
        "# #         print(df)\n",
        "\n",
        "# big_df = pd.concat(my_dfs)\n",
        "# print(big_df)\n",
        "\n",
        "# load in just the fingering for 014-3: Mozart Piano Sonata K 330 in C major, 2nd mov.\n",
        "for filename in os.listdir(directory_path):\n",
        "    file_path = os.path.join(directory_path, filename)\n",
        "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[0]:\n",
        "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
        "        print(filename)\n",
        "        print(df.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "caef95f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "caef95f6",
        "outputId": "c323e27f-3821-4523-acfc-789830da3176"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "noteID             0\n",
              "onset_time         0\n",
              "offset_time        0\n",
              "spelled_pitch      0\n",
              "onset_velocity     0\n",
              "offset_velocity    0\n",
              "channel            0\n",
              "finger_number      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>noteID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>onset_time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>offset_time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spelled_pitch</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>onset_velocity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>offset_velocity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>channel</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finger_number</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a27ee2a7",
      "metadata": {
        "id": "a27ee2a7"
      },
      "source": [
        "# Idea 1: simple linear regression to predict finger_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10eeea16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10eeea16",
        "outputId": "90ed532a-b90a-49cb-c183-d4ab58608a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'A6': 5, 'B1': 6, 'B2': 7, 'B3': 8, 'B4': 9, 'B5': 10, 'B6': 11, 'Bb1': 12, 'Bb2': 13, 'Bb3': 14, 'Bb4': 15, 'Bb5': 16, 'Bb6': 17, 'C#1': 18, 'C#2': 19, 'C#3': 20, 'C#4': 21, 'C#5': 22, 'C#6': 23, 'C#7': 24, 'C1': 25, 'C2': 26, 'C3': 27, 'C4': 28, 'C5': 29, 'C6': 30, 'C7': 31, 'D1': 32, 'D2': 33, 'D3': 34, 'D4': 35, 'D5': 36, 'D6': 37, 'D7': 38, 'E1': 39, 'E2': 40, 'E3': 41, 'E4': 42, 'E5': 43, 'E6': 44, 'E7': 45, 'Eb1': 46, 'Eb2': 47, 'Eb3': 48, 'Eb4': 49, 'Eb5': 50, 'Eb6': 51, 'Eb7': 52, 'F#1': 53, 'F#2': 54, 'F#3': 55, 'F#4': 56, 'F#5': 57, 'F#6': 58, 'F#7': 59, 'F1': 60, 'F2': 61, 'F3': 62, 'F4': 63, 'F5': 64, 'F6': 65, 'F7': 66, 'G#1': 67, 'G#2': 68, 'G#3': 69, 'G#4': 70, 'G#5': 71, 'G#6': 72, 'G1': 73, 'G2': 74, 'G3': 75, 'G4': 76, 'G5': 77, 'G6': 78}\n"
          ]
        }
      ],
      "source": [
        "spelled_pitch_values = set()\n",
        "\n",
        "for filename in os.listdir(directory_path):\n",
        "    file_path = os.path.join(directory_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
        "        spelled_pitch_values.update(df['spelled_pitch'].unique())\n",
        "\n",
        "\n",
        "\n",
        "# convert \"spelled pitch\" field to a number: create the mapping in the first place\n",
        "spelled_pitch_values = sorted(spelled_pitch_values)\n",
        "\n",
        "pitch_to_int_mapping = {p:i for i, p in enumerate(spelled_pitch_values)}\n",
        "\n",
        "# print(len(spelled_pitch_values))\n",
        "# print(len(pitch_to_int_mapping))\n",
        "print(pitch_to_int_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8552f68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8552f68",
        "outputId": "9d4a036e-5f31-4b72-9fa0-2ef7062c6713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x's shape is torch.Size([293, 7])\n",
            "y's shape is torch.Size([293, 1])\n"
          ]
        }
      ],
      "source": [
        "for filename in os.listdir(directory_path):\n",
        "    file_path = os.path.join(directory_path, filename)\n",
        "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[0]:\n",
        "        df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
        "\n",
        "num_data, num_features = df.shape\n",
        "x = df.iloc[:, 0:num_features - 1]\n",
        "y = df.iloc[:, num_features - 1]\n",
        "\n",
        "\n",
        "# convert \"spelled pitch\" field to a number\n",
        "x['spelled_pitch'] = x['spelled_pitch'].map(pitch_to_int_mapping)\n",
        "\n",
        "\n",
        "x = torch.tensor(x.values.tolist(), dtype=torch.float32)\n",
        "y = torch.tensor(y.values.astype(float).tolist())\n",
        "y = y.unsqueeze(1)   # conver from size [289] to size [289, 1]\n",
        "\n",
        "print(f\"x's shape is {x.shape}\")\n",
        "print(f\"y's shape is {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "264b9991",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "264b9991",
        "outputId": "ee3b2418-437a-4253-9544-bde8cc4ed722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num features is 8 and num data is 293\n"
          ]
        }
      ],
      "source": [
        "print(f\"num features is {num_features} and num data is {num_data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e3ebc98b",
      "metadata": {
        "id": "e3ebc98b"
      },
      "outputs": [],
      "source": [
        "# Pytorch code that does the same least squares fitting, but nn.Module-ized. Iterative regression\n",
        "\n",
        "class LinearRegressionBaseline(nn.Module):\n",
        "    def __init__(self, input_dims, output_dims):\n",
        "        super(LinearRegressionBaseline, self).__init__()\n",
        "        self.linear = nn.Linear(input_dims, output_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8dc5b8b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc5b8b6",
        "outputId": "617c6603-a2a7-42d1-89e3-a264f1fddcc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([293, 7])\n",
            "torch.Size([293, 1])\n",
            "torch.Size([293, 1])\n"
          ]
        }
      ],
      "source": [
        "my_linear_model = LinearRegressionBaseline(num_features - 1, 1)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(my_linear_model.parameters(), lr=1e-2)    # Needs a VERY small learning rate, else NaN.\n",
        "\n",
        "\n",
        "# normalize inputs before feeding to model\n",
        "x = (x - x.mean()) / x.std()\n",
        "y = (y - y.mean()) / y.std()\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(my_linear_model(x).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "acc6809c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acc6809c",
        "outputId": "f95dd2bc-bbae-4d27-c986-ed2992b8b311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5000/5000], Loss: 0.7439\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    y_pred = my_linear_model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "#     print(x.shape)\n",
        "#     print(y.shape)\n",
        "#     print(y_pred)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5000 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91667def",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91667def",
        "outputId": "0b31293d-8310-4cb8-9ca9-e26cd9665c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Test Loss: 0.7438\n",
            "Sample Predictions:\n",
            "Predicted: [0.19861197], Actual: [0.17805079]\n",
            "Predicted: [0.17860365], Actual: [1.4822726]\n",
            "Predicted: [0.1981008], Actual: [0.17805079]\n",
            "Predicted: [0.17809272], Actual: [1.1562172]\n",
            "Predicted: [0.19975638], Actual: [0.17805079]\n"
          ]
        }
      ],
      "source": [
        "# Check on testing set\n",
        "\n",
        "x_test = x\n",
        "y_test = y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ensure your model is in evaluation mode\n",
        "my_linear_model.eval()\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    # Forward pass: Predict on the test set\n",
        "    y_test_pred = my_linear_model(x_test)\n",
        "\n",
        "    # Calculate the loss on the test set\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "\n",
        "    # Optional: Convert predictions to numpy for further analysis if needed\n",
        "    y_test_pred_np = y_test_pred.cpu().numpy() if y_test_pred.is_cuda else y_test_pred.numpy()\n",
        "    y_test_np = y_test.cpu().numpy() if y_test.is_cuda else y_test.numpy()\n",
        "\n",
        "# Print the results\n",
        "print(\"Test Results:\")\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(min(5, len(y_test_pred))):  # Display up to 5 predictions\n",
        "    print(f\"Predicted: {y_test_pred_np[i]}, Actual: {y_test_np[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "309a6e06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "309a6e06",
        "outputId": "95bc5eb0-8c1d-4ac2-e912-2014b66ac92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(293, 7)\n",
            "(293,)\n",
            "Weights (Scikit-Learn): [ -87.728645      0.22731297   12.838359    -15.811432      0.13658929\n",
            "    0.22497249    0.22756538 -104.933     ]\n",
            "Test Loss (Scikit-Learn): 0.233975\n"
          ]
        }
      ],
      "source": [
        "# Compare with Scikit Normal Equation Result\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import torch\n",
        "\n",
        "# Assuming x and y are your training tensors\n",
        "x_np = x.numpy() if isinstance(x, torch.Tensor) else x\n",
        "y_np = y.numpy() if isinstance(y, torch.Tensor) else y\n",
        "y_np = y_np.reshape(-1)\n",
        "\n",
        "print(x_np.shape)\n",
        "print(y_np.shape)\n",
        "\n",
        "\n",
        "# Validate with Scikit-Learn\n",
        "lr = LinearRegression(fit_intercept=True)\n",
        "lr.fit(x_np, y_np)\n",
        "\n",
        "# Print Scikit-Learn weights for comparison\n",
        "print(\"Weights (Scikit-Learn):\", np.hstack([lr.intercept_, lr.coef_]))\n",
        "\n",
        "\n",
        "x_test_np = x_np\n",
        "y_test_np = y_np\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = lr.predict(x_test_np)\n",
        "\n",
        "# Compute Mean Squared Error (MSE) loss\n",
        "test_loss = np.mean((y_test_pred - y_test_np) ** 2)\n",
        "\n",
        "# Print the loss\n",
        "print(\"Test Loss (Scikit-Learn):\", test_loss)    # About the same loss: 0.53!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad1572f",
      "metadata": {
        "id": "bad1572f"
      },
      "source": [
        "# Idea 2: Add more layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1104c6b9",
      "metadata": {
        "id": "1104c6b9"
      },
      "outputs": [],
      "source": [
        "# deep neural net with more layers\n",
        "\n",
        "class DeepNeuralNet(nn.Module):\n",
        "    def __init__(self, input_dims, output_dims):\n",
        "        super(DeepNeuralNet, self).__init__()\n",
        "        self.mlp_layer = nn.Sequential(\n",
        "            nn.Linear(input_dims, 4 * input_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * input_dims, output_dims),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e4971d1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4971d1f",
        "outputId": "bd61e5c0-4af4-4212-c77d-7e9c42455337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([293, 7])\n",
            "torch.Size([293, 1])\n",
            "torch.Size([293, 1])\n"
          ]
        }
      ],
      "source": [
        "dnn_model = DeepNeuralNet(num_features - 1, 1)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-2)    # Needs a VERY small learning rate, else NaN.\n",
        "\n",
        "\n",
        "# normalize inputs before feeding to model\n",
        "x = (x - x.mean()) / x.std()\n",
        "y = (y - y.mean()) / y.std()\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(dnn_model(x).shape)\n",
        "\n",
        "\n",
        "# Adding more layers helps a lot!\n",
        "\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    y_pred = dnn_model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "#     print(x.shape)\n",
        "#     print(y.shape)\n",
        "#     print(y_pred)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5000 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44042739",
      "metadata": {
        "id": "44042739"
      },
      "source": [
        "# Testing code\n",
        "\n",
        "Testing on some random other piece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1db253f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1db253f1",
        "outputId": "b2b4c20e-0864-4acf-c971-a11922cebf2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002-5_fingering.txt\n"
          ]
        }
      ],
      "source": [
        "for filename in os.listdir(directory_path):\n",
        "    file_path = os.path.join(directory_path, filename)\n",
        "    if os.path.isfile(file_path) and filename == os.listdir(directory_path)[1]:\n",
        "        test_df = pd.read_table(file_path, sep=\"\\t\", skiprows=1, names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"])\n",
        "        print(filename)\n",
        "\n",
        "x_test = test_df.iloc[:, 0:num_features - 1]\n",
        "y_test = test_df.iloc[:, num_features - 1]\n",
        "\n",
        "x_test['spelled_pitch'] = x_test['spelled_pitch'].map(pitch_to_int_mapping)\n",
        "\n",
        "\n",
        "# print(x_test)\n",
        "\n",
        "# NORMALIZE FIRST\n",
        "# Normalize x_test\n",
        "for col in x_test.columns:\n",
        "    std = x_test[col].std()\n",
        "    if std == 0:  # Check if all values are the same\n",
        "        x_test[col] = 0  # Assign all entries in this column to 0\n",
        "    else:\n",
        "        x_test[col] = (x_test[col] - x_test[col].mean()) / std\n",
        "\n",
        "# Normalize y_test\n",
        "y_test_std = y_test.std()\n",
        "if y_test_std == 0:  # Check if all values are the same\n",
        "    y_test = 0  # Assign all entries in y_test to 0\n",
        "else:\n",
        "    y_test = (y_test - y_test.mean()) / y_test_std\n",
        "\n",
        "\n",
        "\n",
        "x_test = torch.tensor(x_test.values.tolist(), dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values.astype(float).tolist())\n",
        "y_test = y_test.unsqueeze(1)   # conver from size [289] to size [289, 1]\n",
        "\n",
        "\n",
        "# print(y_test)\n",
        "\n",
        "\n",
        "# print(x_test.isna().sum())\n",
        "# print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0c09892c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c09892c",
        "outputId": "5a905fcc-3602-4d25-f8ec-32f4a16e4f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Test Loss: 2091.3459\n",
            "Sample Predictions:\n",
            "Predicted: [-14.536429], Actual: [0.3052198]\n",
            "Predicted: [-24.420633], Actual: [0.64844805]\n",
            "Predicted: [-13.382349], Actual: [0.3052198]\n",
            "Predicted: [-14.38389], Actual: [0.99167633]\n",
            "Predicted: [-12.240117], Actual: [0.3052198]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check on testing set\n",
        "\n",
        "# x_test = x\n",
        "# y_test = y\n",
        "\n",
        "# print(x_test)\n",
        "# print(y_test)\n",
        "\n",
        "\n",
        "# Ensure your model is in evaluation mode\n",
        "dnn_model.eval()\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    # Forward pass: Predict on the test set\n",
        "    y_test_pred = dnn_model(x_test)\n",
        "\n",
        "    # Calculate the loss on the test set\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "\n",
        "    # Optional: Convert predictions to numpy for further analysis if needed\n",
        "    y_test_pred_np = y_test_pred.cpu().numpy() if y_test_pred.is_cuda else y_test_pred.numpy()\n",
        "    y_test_np = y_test.cpu().numpy() if y_test.is_cuda else y_test.numpy()\n",
        "\n",
        "# Print the results\n",
        "print(\"Test Results:\")\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(min(5, len(y_test_pred))):  # Display up to 5 predictions\n",
        "    print(f\"Predicted: {y_test_pred_np[i]}, Actual: {y_test_np[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6bea2b6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bea2b6c",
        "outputId": "973d69e0-6729-4744-8abf-33f5e058bd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANNOTATING FILE: 053-1_fingering.txt\n",
            "Predicted Fingering Sequence for 053-1_fingering.txt:\n",
            "[8, 0, 4, 4, 2, 2, 2, 4, 4, 2, 4, 6, 0, 2, 10, 0, 2, 6, 0, 2, 6, 0, 2, 6, 0, 2, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 4, 2, 2, 2, 4, 4, 2, 4, 6, 0, 2, 10, 0, 2, 6, 0, 2, 7, 0, 2, 7, 0, 2, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 6, 8, 0, 4, 4, 2, 8, 8, 0, 10, 8, 0, 10, 8, 10, 10, 10, 10, 10, 10, 0, 4, 6, 8, 0, 10, 8, 0, 10, 8, 8, 10, 10, 10, 10, 10, 0, 4, 4, 2, 7, 8, 0, 4, 6, 8, 0, 4, 6, 8, 10, 10, 10, 10, 0, 4, 6, 8, 0, 4, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 0, 4, 6, 8, 0, 10, 8, 8, 10, 10, 10, 10, 10, 0, 4, 4, 2, 2, 4, 4, 4, 2, 8, 8, 10, 10, 10, 10, 0, 4, 4, 6, 0, 6, 8, 0, 10, 0, 6, 4, 6, 4, 6, 4, 4, 4, 6, 8, 10, 10, 10, 10, 0, 4, 4, 6, 0, 6, 8, 0, 10, 0, 6, 4, 6, 4, 6, 4, 4, 4]\n",
            "Actual Fingering:\n",
            "[8, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 8, 1, 3, 6, 1, 3, 7, 1, 3, 6, 1, 4, 7, 1, 4, 8, 6, 1, 4, 7, 8, 1, 4, 6, 7, 1, 4, 8, 9, 1, 4, 8, 9, 1, 4, 8, 9, 1, 4, 7, 6, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 8, 1, 3, 6, 1, 3, 7, 1, 3, 6, 1, 4, 7, 1, 4, 8, 6, 1, 4, 7, 8, 1, 4, 6, 7, 1, 4, 8, 9, 1, 4, 8, 9, 1, 4, 8, 9, 1, 4, 7, 6, 1, 3, 1, 3, 7, 8, 4, 7, 10, 1, 9, 8, 7, 6, 9, 8, 7, 8, 1, 3, 7, 8, 4, 7, 10, 1, 9, 8, 7, 6, 8, 7, 6, 7, 0, 4, 0, 4, 6, 7, 0, 4, 6, 9, 0, 4, 8, 7, 6, 9, 8, 7, 1, 3, 6, 7, 2, 4, 6, 8, 6, 8, 7, 9, 8, 9, 8, 7, 6, 9, 8, 7, 2, 4, 8, 6, 3, 7, 6, 7, 8, 9, 8, 9, 6, 1, 2, 3, 4, 3, 4, 3, 4, 0, 8, 8, 7, 8, 7, 9, 0, 4, 2, 8, 4, 7, 6, 1, 8, 4, 7, 3, 9, 4, 8, 3, 1, 4, 8, 8, 7, 8, 7, 9, 1, 4, 3, 8, 4, 7, 6, 0, 7, 4, 8, 2, 6, 4, 7, 1, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Step 1: Load the specific file\n",
        "specific_file = os.listdir(directory_path)[10]  # Replace 10 with the desired index\n",
        "file_path = os.path.join(directory_path, specific_file)\n",
        "\n",
        "my_df = pd.DataFrame()\n",
        "\n",
        "if os.path.isfile(file_path):\n",
        "    print(f\"ANNOTATING FILE: {specific_file}\")\n",
        "    my_df = pd.read_table(\n",
        "        file_path,\n",
        "        sep=\"\\t\",\n",
        "        skiprows=1,\n",
        "        names=[\"noteID\", \"onset_time\", \"offset_time\", \"spelled_pitch\", \"onset_velocity\", \"offset_velocity\", \"channel\", \"finger_number\"]\n",
        "    )\n",
        "\n",
        "\n",
        "column_name = \"finger_number\"  # Replace with the actual column name\n",
        "if not pd.api.types.is_integer_dtype(my_df[column_name]):\n",
        "    my_df.iloc[:, -1] = my_df.iloc[:, -1].where(\n",
        "        ~my_df.iloc[:, num_features - 1].str.contains('_', na=False),\n",
        "        my_df.iloc[:, num_features - 1].str.split('_').str[0]\n",
        "    ).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Normalize and map spelled_pitch\n",
        "my_df['spelled_pitch'] = my_df['spelled_pitch'].map(pitch_to_int_mapping)\n",
        "\n",
        "features = my_df.iloc[:, :-1]\n",
        "labels = my_df.iloc[:, -1].astype(int) + 5  # Adjust labels if necessary for CrossEntropyLoss\n",
        "\n",
        "\n",
        "\n",
        "# Replace NaN or invalid mappings if needed\n",
        "# features.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Normalize features: CAN'T JUST DO MEAN / STD SINCE STD MIGHT BE 0!!!\n",
        "for col in features.columns:\n",
        "    std = features[col].std()\n",
        "    if std == 0:  # Check if all values are the same\n",
        "        features[col] = 0  # Assign all entries in this column to 0\n",
        "    else:\n",
        "        features[col] = (features[col] - features[col].mean()) / std\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x_piece = torch.tensor(features.values, dtype=torch.float32).unsqueeze(0)  # Shape: [1, seq_len, num_features]\n",
        "y_piece = torch.tensor(labels.values, dtype=int).unsqueeze(0)  # Shape: [1, seq_len]\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Create a DataLoader\n",
        "piece_dataset = TensorDataset(x_piece, y_piece)\n",
        "piece_loader = DataLoader(piece_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Step 4: Predict the fingering sequence\n",
        "model.eval()\n",
        "predicted_fingering = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, _ in piece_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        outputs = model(x_batch)  # Shape: [1, seq_len, num_classes]\n",
        "        preds = torch.argmax(outputs, dim=-1)  # Shape: [1, seq_len]\n",
        "        predicted_fingering = preds.squeeze(0).tolist()\n",
        "\n",
        "# Step 5: Output the predictions\n",
        "print(f\"Predicted Fingering Sequence for {specific_file}:\")\n",
        "print(predicted_fingering)\n",
        "\n",
        "\n",
        "# print out actual\n",
        "print(f\"Actual Fingering:\")\n",
        "print(labels.tolist())\n",
        "\n",
        "\n",
        "# print out overall \"loss\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ad653b08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad653b08",
        "outputId": "aea27501-6d4e-48de-da16-c2e5a29fb1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error at pos 1: note is 0 but should be 0\n",
            "error at pos 2: note is 4 but should be 4\n",
            "error at pos 3: note is 4 but should be 4\n",
            "error at pos 4: note is 2 but should be 2\n",
            "error at pos 5: note is 2 but should be 2\n",
            "error at pos 6: note is 2 but should be 2\n",
            "error at pos 7: note is 4 but should be 4\n",
            "error at pos 8: note is 4 but should be 4\n",
            "error at pos 9: note is 2 but should be 2\n",
            "error at pos 10: note is 4 but should be 4\n",
            "error at pos 11: note is 6 but should be 6\n",
            "error at pos 12: note is 0 but should be 0\n",
            "error at pos 13: note is 2 but should be 2\n",
            "error at pos 14: note is 10 but should be 10\n",
            "error at pos 15: note is 0 but should be 0\n",
            "error at pos 16: note is 2 but should be 2\n",
            "error at pos 17: note is 6 but should be 6\n",
            "error at pos 18: note is 0 but should be 0\n",
            "error at pos 19: note is 2 but should be 2\n",
            "error at pos 21: note is 0 but should be 0\n",
            "error at pos 22: note is 2 but should be 2\n",
            "error at pos 23: note is 6 but should be 6\n",
            "error at pos 24: note is 0 but should be 0\n",
            "error at pos 25: note is 2 but should be 2\n",
            "error at pos 26: note is 6 but should be 6\n",
            "error at pos 27: note is 8 but should be 8\n",
            "error at pos 28: note is 0 but should be 0\n",
            "error at pos 30: note is 6 but should be 6\n",
            "error at pos 32: note is 0 but should be 0\n",
            "error at pos 35: note is 8 but should be 8\n",
            "error at pos 36: note is 0 but should be 0\n",
            "error at pos 38: note is 6 but should be 6\n",
            "error at pos 39: note is 8 but should be 8\n",
            "error at pos 40: note is 0 but should be 0\n",
            "error at pos 42: note is 6 but should be 6\n",
            "error at pos 43: note is 8 but should be 8\n",
            "error at pos 44: note is 0 but should be 0\n",
            "error at pos 46: note is 6 but should be 6\n",
            "error at pos 47: note is 8 but should be 8\n",
            "error at pos 48: note is 0 but should be 0\n",
            "error at pos 50: note is 6 but should be 6\n",
            "error at pos 51: note is 8 but should be 8\n",
            "error at pos 52: note is 0 but should be 0\n",
            "error at pos 53: note is 4 but should be 4\n",
            "error at pos 54: note is 4 but should be 4\n",
            "error at pos 55: note is 2 but should be 2\n",
            "error at pos 56: note is 2 but should be 2\n",
            "error at pos 57: note is 2 but should be 2\n",
            "error at pos 58: note is 4 but should be 4\n",
            "error at pos 59: note is 4 but should be 4\n",
            "error at pos 60: note is 2 but should be 2\n",
            "error at pos 61: note is 4 but should be 4\n",
            "error at pos 62: note is 6 but should be 6\n",
            "error at pos 63: note is 0 but should be 0\n",
            "error at pos 64: note is 2 but should be 2\n",
            "error at pos 65: note is 10 but should be 10\n",
            "error at pos 66: note is 0 but should be 0\n",
            "error at pos 67: note is 2 but should be 2\n",
            "error at pos 68: note is 6 but should be 6\n",
            "error at pos 69: note is 0 but should be 0\n",
            "error at pos 70: note is 2 but should be 2\n",
            "error at pos 71: note is 7 but should be 7\n",
            "error at pos 72: note is 0 but should be 0\n",
            "error at pos 73: note is 2 but should be 2\n",
            "error at pos 75: note is 0 but should be 0\n",
            "error at pos 76: note is 2 but should be 2\n",
            "error at pos 77: note is 6 but should be 6\n",
            "error at pos 78: note is 8 but should be 8\n",
            "error at pos 79: note is 0 but should be 0\n",
            "error at pos 81: note is 6 but should be 6\n",
            "error at pos 83: note is 0 but should be 0\n",
            "error at pos 86: note is 8 but should be 8\n",
            "error at pos 87: note is 0 but should be 0\n",
            "error at pos 89: note is 6 but should be 6\n",
            "error at pos 90: note is 8 but should be 8\n",
            "error at pos 91: note is 0 but should be 0\n",
            "error at pos 93: note is 6 but should be 6\n",
            "error at pos 94: note is 8 but should be 8\n",
            "error at pos 95: note is 0 but should be 0\n",
            "error at pos 97: note is 6 but should be 6\n",
            "error at pos 98: note is 8 but should be 8\n",
            "error at pos 99: note is 0 but should be 0\n",
            "error at pos 101: note is 6 but should be 6\n",
            "error at pos 102: note is 8 but should be 8\n",
            "error at pos 103: note is 0 but should be 0\n",
            "error at pos 104: note is 4 but should be 4\n",
            "error at pos 105: note is 4 but should be 4\n",
            "error at pos 106: note is 2 but should be 2\n",
            "error at pos 107: note is 8 but should be 8\n",
            "error at pos 109: note is 0 but should be 0\n",
            "error at pos 110: note is 10 but should be 10\n",
            "error at pos 111: note is 8 but should be 8\n",
            "error at pos 112: note is 0 but should be 0\n",
            "error at pos 113: note is 10 but should be 10\n",
            "error at pos 115: note is 10 but should be 10\n",
            "error at pos 116: note is 10 but should be 10\n",
            "error at pos 117: note is 10 but should be 10\n",
            "error at pos 118: note is 10 but should be 10\n",
            "error at pos 119: note is 10 but should be 10\n",
            "error at pos 120: note is 10 but should be 10\n",
            "error at pos 121: note is 0 but should be 0\n",
            "error at pos 122: note is 4 but should be 4\n",
            "error at pos 123: note is 6 but should be 6\n",
            "error at pos 125: note is 0 but should be 0\n",
            "error at pos 126: note is 10 but should be 10\n",
            "error at pos 127: note is 8 but should be 8\n",
            "error at pos 128: note is 0 but should be 0\n",
            "error at pos 129: note is 10 but should be 10\n",
            "error at pos 131: note is 8 but should be 8\n",
            "error at pos 132: note is 10 but should be 10\n",
            "error at pos 133: note is 10 but should be 10\n",
            "error at pos 134: note is 10 but should be 10\n",
            "error at pos 135: note is 10 but should be 10\n",
            "error at pos 136: note is 10 but should be 10\n",
            "error at pos 139: note is 4 but should be 4\n",
            "error at pos 140: note is 2 but should be 2\n",
            "error at pos 141: note is 7 but should be 7\n",
            "error at pos 142: note is 8 but should be 8\n",
            "error at pos 146: note is 8 but should be 8\n",
            "error at pos 149: note is 6 but should be 6\n",
            "error at pos 150: note is 8 but should be 8\n",
            "error at pos 151: note is 10 but should be 10\n",
            "error at pos 152: note is 10 but should be 10\n",
            "error at pos 153: note is 10 but should be 10\n",
            "error at pos 154: note is 10 but should be 10\n",
            "error at pos 155: note is 0 but should be 0\n",
            "error at pos 156: note is 4 but should be 4\n",
            "error at pos 158: note is 8 but should be 8\n",
            "error at pos 159: note is 0 but should be 0\n",
            "error at pos 163: note is 10 but should be 10\n",
            "error at pos 164: note is 10 but should be 10\n",
            "error at pos 165: note is 10 but should be 10\n",
            "error at pos 166: note is 10 but should be 10\n",
            "error at pos 167: note is 10 but should be 10\n",
            "error at pos 168: note is 10 but should be 10\n",
            "error at pos 169: note is 10 but should be 10\n",
            "error at pos 170: note is 10 but should be 10\n",
            "error at pos 171: note is 10 but should be 10\n",
            "error at pos 172: note is 10 but should be 10\n",
            "error at pos 173: note is 10 but should be 10\n",
            "error at pos 174: note is 10 but should be 10\n",
            "error at pos 175: note is 0 but should be 0\n",
            "error at pos 177: note is 6 but should be 6\n",
            "error at pos 178: note is 8 but should be 8\n",
            "error at pos 179: note is 0 but should be 0\n",
            "error at pos 180: note is 10 but should be 10\n",
            "error at pos 181: note is 8 but should be 8\n",
            "error at pos 182: note is 8 but should be 8\n",
            "error at pos 183: note is 10 but should be 10\n",
            "error at pos 184: note is 10 but should be 10\n",
            "error at pos 185: note is 10 but should be 10\n",
            "error at pos 186: note is 10 but should be 10\n",
            "error at pos 187: note is 10 but should be 10\n",
            "error at pos 188: note is 0 but should be 0\n",
            "error at pos 189: note is 4 but should be 4\n",
            "error at pos 190: note is 4 but should be 4\n",
            "error at pos 191: note is 2 but should be 2\n",
            "error at pos 192: note is 2 but should be 2\n",
            "error at pos 194: note is 4 but should be 4\n",
            "error at pos 196: note is 2 but should be 2\n",
            "error at pos 199: note is 10 but should be 10\n",
            "error at pos 200: note is 10 but should be 10\n",
            "error at pos 201: note is 10 but should be 10\n",
            "error at pos 202: note is 10 but should be 10\n",
            "error at pos 205: note is 4 but should be 4\n",
            "error at pos 206: note is 6 but should be 6\n",
            "error at pos 207: note is 0 but should be 0\n",
            "error at pos 208: note is 6 but should be 6\n",
            "error at pos 209: note is 8 but should be 8\n",
            "error at pos 210: note is 0 but should be 0\n",
            "error at pos 211: note is 10 but should be 10\n",
            "error at pos 212: note is 0 but should be 0\n",
            "error at pos 213: note is 6 but should be 6\n",
            "error at pos 214: note is 4 but should be 4\n",
            "error at pos 215: note is 6 but should be 6\n",
            "error at pos 217: note is 6 but should be 6\n",
            "error at pos 218: note is 4 but should be 4\n",
            "error at pos 219: note is 4 but should be 4\n",
            "error at pos 221: note is 6 but should be 6\n",
            "error at pos 223: note is 10 but should be 10\n",
            "error at pos 224: note is 10 but should be 10\n",
            "error at pos 225: note is 10 but should be 10\n",
            "error at pos 226: note is 10 but should be 10\n",
            "error at pos 227: note is 0 but should be 0\n",
            "error at pos 229: note is 4 but should be 4\n",
            "error at pos 230: note is 6 but should be 6\n",
            "error at pos 231: note is 0 but should be 0\n",
            "error at pos 232: note is 6 but should be 6\n",
            "error at pos 233: note is 8 but should be 8\n",
            "error at pos 235: note is 10 but should be 10\n",
            "error at pos 236: note is 0 but should be 0\n",
            "error at pos 237: note is 6 but should be 6\n",
            "error at pos 238: note is 4 but should be 4\n",
            "error at pos 241: note is 6 but should be 6\n",
            "error at pos 242: note is 4 but should be 4\n",
            "error at pos 243: note is 4 but should be 4\n",
            "num_wrong is 196\n",
            "len(preds) is 245\n",
            "Overall Accuracy: 20.00%\n"
          ]
        }
      ],
      "source": [
        "# print metrics for a specific piece\n",
        "labels = labels.tolist()\n",
        "\n",
        "# Calculate model loss and accuracy\n",
        "def calc_metrics(preds, actuals, criterion):\n",
        "    \"\"\"\n",
        "    Calculate the Cross-Entropy loss and accuracy for the predicted vs. actual labels.\n",
        "    \"\"\"\n",
        "\n",
        "    num_wrong = 0\n",
        "\n",
        "    if len(preds) != len(actuals):\n",
        "        print(\"preds and actuals not of same size\")\n",
        "        return\n",
        "\n",
        "    for i, value in enumerate(preds):\n",
        "        if value != actuals[i]:\n",
        "            num_wrong += 1\n",
        "            print(f\"error at pos {i}: note is {value} but should be {preds[i]}\")\n",
        "\n",
        "    print(f\"num_wrong is {num_wrong}\")\n",
        "    print(f\"len(preds) is {len(preds)}\")\n",
        "\n",
        "    accuracy = 1 - (num_wrong / len(preds))\n",
        "    return accuracy\n",
        "\n",
        "# print(predicted_fingering)\n",
        "# print(labels.tolist())\n",
        "# Calculate overall loss and accuracy\n",
        "overall_accuracy = calc_metrics(predicted_fingering, labels, criterion)\n",
        "\n",
        "# Print the overall loss and accuracy\n",
        "# print(f\"Overall Loss: {overall_loss:.4f}\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing if Chinese reward model works"
      ],
      "metadata": {
        "id": "bLEXdPp9IXAA"
      },
      "id": "bLEXdPp9IXAA"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2b67f2bd",
      "metadata": {
        "id": "2b67f2bd"
      },
      "outputs": [],
      "source": [
        "from reward import PianoFingeringModel, Hand, Finger, Note, NoteFingerPair\n",
        "reward_model = PianoFingeringModel()\n",
        "\n",
        "# ADD CODE HERE THAT TESTS THE REWARD MODEL.\n",
        "# Specifically, I want to essentially run the reward signal over the (probably bad)\n",
        "# linear regression fingering predictions and the ground truth fingering.\n",
        "# I want to be able to tell if the reward model is working as expected if it assigns high\n",
        "# reward to the ground truth and low reward to the bad predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b48a05",
      "metadata": {
        "id": "73b48a05"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ed0aa4",
      "metadata": {
        "id": "91ed0aa4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e7f5a6",
      "metadata": {
        "id": "21e7f5a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e53439",
      "metadata": {
        "id": "c4e53439"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (smol)",
      "language": "python",
      "name": "smol"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}